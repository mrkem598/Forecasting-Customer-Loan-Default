> test <- lenses[-train_ind,]
?floor
lenses <- predict(model_ctree, newdata = lenses)
lenses <- predict(lenses, newdata = lenses)
?predict
lenses <- predict(lenses, newdata = test)
lenses <- predict(lenses, newdata = test)
library(caret)
packag(caret)
library(stringi)
package(caret)
model <- rpart(y~.,traindata, minbucket=5)
?rpart
lenses <- rpart()
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
fit <- rpart(train_ind~., data=train_ind, method = "Class")
fit <- rpart(train_ind~., data=lenses, method = "Class")
fit <- rpart(train_ind~., data=lenses, method = "Class")
lenses
View(lenses)
View(lenses)
View(lenses)
View(lenses)
View(lenses)
library(read.csv)
lenses <- read.csv("~/Desktop/lenses.csv")
View(lenses)
library(read.csv)
lenses <- read.csv("~/Desktop/lenses.csv")
View(lenses)
library(read.csv)
lenses <- read.csv("~/Desktop/lenses.csv")
View(lenses)
lenses$Age <- replace(lenses$Age, lenses$Age == 1, "Young")
> lenses$Age <- replace(lenses$Age, lenses$Age == 2, "Adult")
> lenses$Age <- replace(lenses$Age, lenses$Age == 3, "Old")
> lenses$Sight <- replace(lenses$Sight, lenses$Sight == 1, "Near Sightedness")
> lenses$Sight <- replace(lenses$Sight, lenses$Sight == 2, "Far Sightedness")
> lenses$Astigmatism <- replace(lenses$Astigmatism, lenses$Astigmatism == 1, "Astigmatic")
> lenses$Astigmatism <- replace(lenses$Astigmatism, lenses$Astigmatism == 2, "Non-astigmatic")
> lenses$Tear.Production <- replace(lenses$Tear.Production, lenses$Tear.Production == 1, "Reduced")
> lenses$Tear.Production <- replace(lenses$Tear.Production, lenses$Tear.Production == 2, "Normal")
lenses$Age <- replace(lenses$Age, lenses$Age == 1, "Young")>lenses$Age <- replace(lenses$Age, lenses$Age == 2, "Adult")
> lenses$Age <- replace(lenses$Age, lenses$Age == 3, "Old")
> lenses$Sight <- replace(lenses$Sight, lenses$Sight == 1, "Near Sightedness")
> lenses$Sight <- replace(lenses$Sight, lenses$Sight == 2, "Far Sightedness")
> lenses$Astigmatism <- replace(lenses$Astigmatism, lenses$Astigmatism == 1, "Astigmatic")
> lenses$Astigmatism <- replace(lenses$Astigmatism, lenses$Astigmatism == 2, "Non-astigmatic")
> lenses$Tear.Production <- replace(lenses$Tear.Production, lenses$Tear.Production == 1, "Reduced")
> lenses$Tear.Production <- replace(lenses$Tear.Production, lenses$Tear.Production == 2, "Normal")
lenses$Age <- replace(lenses$Age, lenses$Age == 1, "Young")
lenses$Age <- replace(lenses$Age, lenses$Age == 2, "Adult")
> lenses$Age <- replace(lenses$Age, lenses$Age == 3, "Old")
> lenses$Sight <- replace(lenses$Sight, lenses$Sight == 1, "Near Sightedness")
> lenses$Sight <- replace(lenses$Sight, lenses$Sight == 2, "Far Sightedness")
> lenses$Astigmatism <- replace(lenses$Astigmatism, lenses$Astigmatism == 1, "Astigmatic")
> lenses$Astigmatism <- replace(lenses$Astigmatism, lenses$Astigmatism == 2, "Non-astigmatic")
> lenses$Tear.Production <- replace(lenses$Tear.Production, lenses$Tear.Production == 1, "Reduced")
> lenses$Tear.Production <- replace(lenses$Tear.Production, lenses$Tear.Production == 2, "Normal")
lenses$Age <- replace(lenses$Age, lenses$Age == 2, "Adult")
lenses$Age <- replace(lenses$Age, lenses$Age == 3, "Old")
lenses$Sight <- replace(lenses$Sight, lenses$Sight == 1, "Near Sightedness")
lenses$Sight <- replace(lenses$Sight, lenses$Sight == 2, "Far Sightedness")
lenses$Astigmatism <- replace(lenses$Astigmatism, lenses$Astigmatism == 1, "Astigmatic")
lenses$Astigmatism <- replace(lenses$Astigmatism, lenses$Astigmatism == 2, "Non-astigmatic")
lenses$Tear.Production <- replace(lenses$Tear.Production, lenses$Tear.Production == 1, "Reduced")
lenses$Tear.Production <- replace(lenses$Tear.Production, lenses$Tear.Production == 2, "Normal")
lenses$Class <- replace(lenses$Class, lenses$Class == 3, "None")
lenses$Class <- replace(lenses$Class, lenses$Class == 2, "Soft")
lenses$Class <- replace(lenses$Class, lenses$Class == 1, "Hard")
lenses
create_train_test(lenses, size = 0.83, train = TRUE)
lenses <- create_train_test(lenses, size = 0.83, train = TRUE)
train <- train_ind(lenses, 0.83, train = TRUE)
<- create_train_test(clean_titanic, 0.8, train = FALSE)
dim(data_train)
rpart(formula, data=, method='')
rpart(formula, data=, method='')
lenses <- rpart(lenses$Class, data = train, method = 'Class')
lenses <- rpart(lenses$Class, data = train_ind, method = 'Class')
lenses <- rpart(lenses$Class, data = testInheritedMethods(), method = 'Class')
lenses <- rpart(lenses$Class, data = train_ind, method = 'Class')
lenses <- rpart(lenses$Class, data = test, method = 'Class')
predict(fitted_model, lenses, type = 'Class')
predict(lenses, lenses$Class, type = 'Class')
?load
loadcsv("~/Desktops/votes.csv")
library(read.csv)
dataset <- read.csv("~/Desktops/votes.csv")
View(dataset)
votes = read.csv("~/Desktops/votes.csv")
View(dataset)
votes = read.csv("~/Desktops/votes.csv")
votes = read.csv("~/Desktop/votes.csv")
votes = read.csv("~/Desktop/votes.csv")
votes
summary(votes)
votes = read.csv("~/Desktop/votes.csv")
votes
summary(votes)
?itemfrequency
?frequency
votes <- itemFrequency(votes, type = "absolute")
itemFrequency(votes, itemsets = FALSE, type = c("absolute", "relative"))
install.packages("arulesViz")
library('arules')
?itemFrequency
votes <- itemFrequency(votes, type = "absolute") head(sort(votes, decreasing = TRUE))
votes <- itemFrequency(votes, type = "class") head(sort(votes, decreasing = TRUE))
votes <- itemFrequency(votes) head(sort(votes, decreasing = TRUE))
votes <- itemFrequency(votes) head(sort(votes$Class, decreasing = TRUE))
data("republican")
votes("republican")
votes("class")
library("arulesViz")
library("arulesViz")
data("votes")
length(votes)
data("Votes")
size(votes)
size(votes)
inspect(votes[1:5])
read.csv("~/Desktop/house-votes-84.data.csv")
data("house-votes-84.data")
inspect(votes)
print(votes)
print(house-votes-84.data)
itemFrequencyPlot(votes)
itemFrequencyPlot(votes, n=20, type = "absolute")
itemFrequencyPlot(votes, topN=20, type = "absolute")
itemFrequencyPlot(votes, topN=20)
?itemFrequencyPlot
itemFrequencyPlot(votes, type= c("relative"))
install.packages("frequency")
inspect(votes)
votes <- inspect(votes)
install.packages("libssl-dev")
install.packages("libssl-dev")
$sudo apt-get install libssl-dev
sudo apt-get install libssl-dev
library(arules)
class(votes)
inspect(head(votes, 3))
inspect(head(data.frame(votes), 3))
votes
votes<- as (myDataFrame, "transactions")
frequentItems <- eclat(votes, parameter = list(supp = 0.07, maxlen = 15))
inspect(frequentItems)
itemFrequencyPlot(votes, topN=2, type="absolute", main="Democrat and Republican Frequency")
library(arules)
library(arulesViz)
library(datasets)
itemFrequencyPlot(votes, topN=2, type="absolute")
read.csv("`~/Desktop/groceries.csv")
read.csv("~/Desktop/groceries.csv")
read.csv("~/Desktop/groceries.csv")
groceries
read.csv("~/Desktop/groceries.csv")
print(groceries)
read.csv("~/Desktop/groceries.csv")
dataset <- read.csv("~/Desktop/groceries.csv")
View(dataset)
dataset
groceries <- read.csv("~/Desktop/groceries")
groceries <- read.csv("~/Desktop/groceries.csv")
library(arules)
library(arulesViz)
library(datasets)
data("Groceries")
itemFrequencyPlot(Groceries, topN=20, type="absolute")
votes <- read.csv("~/Desktop/votes.csv")
library(arules)
library(arulesViz)
library(datasets)
votes <- read.csv("~/Desktop/votes.csv")
votes
library(arules)
library(arulesViz)
library(datasets)
itemFrequencyPlot(votes, topN=2, type="absolute")
itemFrequencyPlot(groceries, topN=20, type="absolute")
itemFrequencyPlot(Groceries, topN=20, type="absolute")
itemFrequencyPlot(Groceries, topN=20, type="absolute")
rules <- apriori(Groceries, parameter = list(supp = 0.001, conf = 0.8))
options(digits =2)
inspect(rules[1:5])
library(arules)
library(Matrix)
library(lattice)
library(arulesViz)
summary(votes)
itemFrequency(votes, type="absolute")
methods(itemFrequency())
methods(itemFrequency(votes))
itemFrequency(votes[,1])
inspect(votes)
ispect(votes[1:3])
inspect(votes[1:3])
data(package="arules")
votes <- read.transactions("~/Desktop/votes.csv")
votes
itemFrequency(votes)
summery(votes)
votes
summary(votes)
435*342
435*342*0.0029
itemFrequency(votes)
summary(votes)
itemFrequency(votes,[1:2])
itemFrequency(votes)
itemFrequencyPlot(votes)
inspect(votes)
inspect(votes[1:5])
itemFrequencyPlot(votes, topN=10, type="absolute")
votesSets <- apriori(votes, parameter = list(minlen=1, maxlen=1, target+"frequency votesSets"))
votesSets <- apriori(votes, parameter = list(minlen=1, maxlen=1, target="frequency votesSets"))
votesSets <- apriori(votes, parameter = list(minlen=1, maxlen=1, target="democrat"))
votesSets <- apriori(votes, parameter = list(minlen=1, maxlen=1, target="democrat"))
rules<-apriori(votes,parameter = list(support(=0.001, confidence=0.6, target="rules")))
rules<-apriori(votes,parameter = list(support(=0.001, confidence=0.6)))
rules<-apriori(votes,parameter = list(support(=0.001, confidence=0.6, target="rules")))
rules<-apriori(data = votes,parameter = list(supp=0.001, conf=0.0))
inspect(head(sort(rules, by="lift"),10))
library(dplyr)
iris <- read.csv("~/Desktop/iris.csv")
iris
library(dplyr)
?colnames
colnames(iris)
colnames(iris)
colnames(iris) <- c("sepal_length","sepal_width","petal_length","petal_width","class")
iris
pacman::p_load(arules, arulesViz)
install.packages("pacman")
pacman::p_load(arules, arulesViz)
library(datasets)
head(iris)
str(iris)
summary(iris)
iris.one<- iris[,c(1,2,3,4)]
iris.class<- iris[,"class"]
head(iris.one)
head(iris.class)
normalize<- function(x) {}
normalize<- function(x) {return((x-min(x))/(max(x)-min(x)))}
iris.new$sepal_length<- normalize(iris.new$sepal_length)
iris.one$sepal_length<- normalize(iris.new$sepal_length)
iris.one$sepal_length<- normalize(iris.one$sepal_length)
iris.one$sepal_width<- normalize(iris.one$sepal_width)
iris.one$petal_length<- normalize(iris.one$petal_length)
iris.one$petal_width<- normalize(iris.one$petal_width)
head(iris.one)
kmeans_sepal <- data.frame(iris.one$sepal_length, iris.one$sepal_width)
kmeans_petal <- data.frame(iris.one$petal_length, iris.one$petal_width)
# apply k-means algorithm with 3 centroids k=3
result<- kmeans(iris.one,3)
result$size
#To get values of cluster center datapoint value 3 for k=3
result$centers
# To get cluster vector that shows cluster where each record fails
result$cluster
# Plot the outcome of your clustering model using clusplot R command, #e.g., clusplot(iris, sepal$cluster, color=TRUE, shade=TRUE, labels=, lines=0).
For the kmeans_petal variables, run the k-means algorithm for 4 clusters and plot the outcome.
Note that to use the clusplot R command, you need to load cluster library.
# Plot the outcome of your clustering model using clusplot R command, #e.g., #clusplot(iris, sepal$cluster, color=TRUE, shade=TRUE, labels=, lines=0).
#For the kmeans_petal variables, run the k-means algorithm for 4 clusters and #plot the outcome.
#Note that to use the clusplot R command, you need to load cluster library.
par(mfrow=c(2,2), mar=c(5,4,2,2))
plot(iris.one[c(1,2)], col=result$cluster) #show sepal length and width
plot(iris.one[c(1,2)], col=result$cluster)
clusplot(iris.one, sepal_length$cluster, color=TRUE, shade=TRUE, labels=, lines=0)
plot(iris.one, sepal_length$cluster, color=TRUE, shade=TRUE, labels=, lines=0)
plot(iris.one[c(1,2)], shade=TRUE, col=result$cluster)
library(cluster)
clusplot(iris.one, sepal_length$cluster, color=TRUE, shade=TRUE, labels=, lines=0)
clusplot(iris.one$cluster, color=TRUE, shade=TRUE, labels=, lines=0)
clusplot(iris.one[c(1,2)], shade=TRUE, col=result$cluster)
plot(iris.one[c(1,2)], shade=TRUE, col=result$cluster)
#Shows sepal length and width data points have been distributed originally as per "class" attributes in dataser
plot(iris.one[c(1,2)], col=iris.one.class)
plot(iris.one[c(1,2)], col=iris.one$class)
plot(iris.one[c(1,2)], col=iris.one$class)
plot(iris.one[c(1,2)], color=TRUE, col=iris.one$cluster)
plot(iris.one$cluster, color=TRUE, shade=TRUE, labels=, lines=0)
plot(iris.one[c(1,2)], color=TRUE, col=iris.class)
#petal length and petal width
plot(iris.one[c(3,4)], col=result$cluster, colors=TRUE)
plot(iris.one[c(3,4)], col=iris.class, colors=TRUE)
table(result$cluster, iris.class)
table(result$cluster, iris.class)
library(arules)
library(arules)
library(arulesViz)
library(datasets)
votes
votes
votes <- read.csv("~/Desktop/votes.csv")
head(votes)
colnames(votes)
votes <- read.csv("~/Desktop/votes.csv", header = FALSE)
votes
summary(votes)
votes <- read.csv("~/Desktop/votes.csv", header = TRUE)
votes
head(votes)
head(votes)
summary(votes)
votes <- read.transactions("~/Desktop/votes.csv")
itemFrequency(votes)
library(arules)
library(arulesViz)
votes <- read.csv("~/Desktop/votes.csv", stringsAsFactors = TRUE, col.names = c("col1","col2",....,"colN"))
votes <- read.csv("~/Desktop/votes.csv", stringsAsFactors = TRUE, col.names = c("col1","col2","col3","col4","col5","col6","col7","col8","col9","col10","col11","col12","col13","col14","col15","col16","col17"))
head(votes)
?stringasfactors
colnames(votes)
votes
library(arules)
library(arulesViz)
library(arules)
votes <- t_votes = as(votes, "transactions")
t_votes = as(votes, "transactions")
#convert the dataset to transaction
itemFrequency(t_votes)
itemFrequency(t_votes)
?itemFrequency
#Use R Command itemFrequency methods to get the frequency/support for all single items in in the t_votes dataset based on itemMatrix.
itemFrequency(t_votes)
summary(t_votes)
itemFrequencyPlot(t_votes)
inspect(t_votes)
inspect(t_votes[1:5])
?inspect
library(plotly)
itemFrequencyPlot(t_votes)
itemFrequencyPlot(t_votes, topN=10, type="absolute")
?itemFrequencyPlot
#Provides the generic function itemFrequencyPlot and the S4 method to create an item frequency bar plot for inspecting the item frequency distribution for votes based on itemMatrix
itemFrequencyPlot(t_votes, type = ("relative"), support=NULL, topN = 10)
itemFrequencyPlot(t_votes, type = ("absolute"), support=NULL, topN = 10)
itemFrequencyPlot(t_votes, type = ("absolute"))
itemFrequencyPlot(t_votes, type = ("absolute"))
inspect(head(t_votes,3))
frequentItems <- eclat(t_votes, parameter = list(supp = 0.07, maxlen = 10))
inspect(frequentItems)
frequentItems <- eclat(t_votes, parameter = list(supp = 0.07, maxlen = 10))
inspect(frequentItems)
#Now I will use min supp as 0.001, and conf as 0.8 to create the first rule.
rule1 <- apriori(t_votes, parameter = list(supp=0.001, conf=0.05))
#Arrange high-confidence rules as follow
rules_confidence <- sort(rule1, by="confidence", decreasing = TRUE)
rule1 <- apriori(t_votes, parameter = list(supp=0.001, conf=0.05))
rule <- apriori(t_votes, parameter = list(supp=0.001, confi=0.05))
rules_conf <- sort(rules, by="confidence", decreasing=TRUE)
#Show the support, lift and conf
inspect(head(rules_conf))
rules_confidence <- sort(rule1, by="confidence", decreasing = TRUE)
rule <- apriori(t_votes, parameter = list(supp=0.001, confi=0.05))
# Print the confidence
rules_conf <- sort(rules, by="confidence", decreasing = TRUE)
rules_conf <- sort(rule, by="confidence", decreasing = TRUE)
inspect(t_votes)
rule <- apriori(t_votes, parameter = list(supp=0.001, confi=0.08))
head(t_votes)
inspect(t_votes)
inspect(head(rule))
inspect(head(t_votes))
itemFrequencyPlot(t_votes)
itemFrequencyPlot(t_votes)
itemFrequencyPlot(t_votes)
itemFrequencyPlot(t_votes)
rules <- apriori (data=t_votes, parameter=list (supp=0.001,conf = 0.15,minlen=2), appearance = list(lhs="democrat"), control = list (verbose=F))
rules <- apriori (data=t_votes, parameter=list (supp=0.001,conf = 0.15,minlen=2), appearance = list(lhs="col1"), control = list (verbose=F))
rules <- apriori (data=t_votes, parameter=list (supp=0.001,conf = 0.15,minlen=2), appearance = list(lhs="col1=democrat"), control = list (verbose=F))
rules <- apriori (data=t_votes, parameter=list (supp=0.001,conf = 0.15,minlen=2), appearance = list(lhs="col1=democrat"), control = list (verbose=F))
rules <- apriori (data=t_votes, parameter=list (supp=0.001,conf = 0.15,minlen=2), appearance = list(lhs="col17"), control = list (verbose=F))
rules <- apriori (data=t_votes, parameter=list (supp=0.001,conf = 0.15,minlen=2), appearance = list(lhs="republican"), control = list (verbose=F))
inspect(head(rules))
rules <- apriori (data=t_votes, parameter=list (supp=0.001,conf = 0.15,minlen=2), appearance = list(lhs="col1=republican"), control = list (verbose=F))
inspect(head(rules))
rules <- apriori (data=t_votes, parameter=list (supp=0.115,conf = 0.80,minlen=2), appearance = list(lhs="col1=republican"), control = list (verbose=F))
inpect(head(rules))
inspect(head(rules))
inspect(rules
inspect(rules)
inspect(rules)
rules <- apriori (data=t_votes, parameter=list (supp=0.115,conf = 0.80,minlen=2), appearance = list(lhs="col1=democrat"), control = list (verbose=F))
inspect(rules)
inspect(rules)
rules <- apriori (data=t_votes, parameter=list (supp=0.115,conf = 0.80,minlen=2), appearance = list(lhs="col1=democrat"), control = list (verbose=F))
inspect(rules)
plot(rules)
plot(rules)
plot(rules[1:20], method="graphy", control=list(type="items"))
plot(rules)
iris<- read.csv("~/Desktop/iris.csv", stringAsFactors = TRUE, col.names = c("col1","col2","col3","col4","col5"))
iris<- read.csv("~/Desktop/iris.csv", stringsAsFactors = TRUE, col.names = c("col1","col2","col3","col4","col5"))
summary(iris)
iris.one<- iris[,c(1,2,3,4)]
iris.class<- iris[,"col5"]
head(iris.one)
c
head(iris.class)
normalize<- function(x){}
normalize<- function(x){return((x-min(x)-min(x)))}
iris.one$col1<- normalize(iris.one$col1)
iris.one$col1<- normalize(iris.one$col1)
iris.one$col2<- normalize(iris.one$col2)
iris.one$col3<- normalize(iris.one$col3)
iris.one$col4<- normalize(iris.one$col4)
head(iris.one)
kmeans_sepal <- data.frame(iris.one$col1, iris.one$col2)
kmeans_petal <- data.frame(iris.one$col3, iris.one$col4)
#apply k-means with three centroids
result <- kmeans(iris.one,3)
result$size
result$centers
result$cluster
table(result$cluster, iris.class)
library(cluster)
clusplot(iris,sepal$cluster, color = TRUE, labels = 5, lines = 0)
clusplot(iris,sepal$cluster, shade = TRUE, color = TRUE, labels = 5, lines = 0)
clusplot(iris,sepal_length$cluster, shade = TRUE, color = TRUE, labels = 5, lines = 0)
clusplot(iris,col1$cluster, shade = TRUE, color = TRUE, labels = 5, lines = 0)
clusplot(iris,col2rgb()$cluster, shade = TRUE, color = TRUE, labels = 5, lines = 0)
library(dplyr)
clusplot(iris,col2rgb()$cluster, shade = TRUE, color = TRUE, labels = 5, lines = 0)
clusplot(iris,sepal$cluster, shade = TRUE, color = TRUE, labels = 5, lines = 0)
clusplot(iris,sepal_length$cluster, shade = TRUE, color = TRUE, labels = 5, lines = 0)
clusplot(iris,col(col1))
clusplot(iris,col())
clusplot(iris,col(sepal_length))
result <- kmeans(iris.one,4)
result$size
result$centers
result$cluster
table(result$cluster, iris.class)
result <- kmeans(iris.one,2)
result$size
result$centers
table(result$cluster, iris.class)
plot(result$cluster, iris.class)
result <- kmeans(iris.one,3)
result$size
result$centers
result$cluster
table(result$cluster, iris.class)
load("~/moh/.RData")
import numpy as np
import numpy as np
LoanDataRaw <- read.csv(csv_Downloads/LoanData.csv, header = TRUE, SEP=",",na.strings = c("","","NA"))
LoanDataRaw <- read.csv("csv_Downloads/LoanData.csv", header = TRUE, SEP=",",na.strings = c("","","NA"))
LoanDataRaw <- read.csv("Downloads/LoanData.csv", header = TRUE, SEP=",",na.strings = c("","","NA"))
library(readr)
LoanData <- read_csv("~/Downloads/LoanData.csv")
View(LoanData)
library(readr)
LoanData <- read_csv("~/Downloads/LoanData.csv")
View(LoanData)
LoanData = read.csv('~/Downloads/LoanData.csv')
LoanData = read.csv('~/Downloads/LoanData.csv', header = TRUE, sep = ",", na.strings = c(""," ","NA"))
LoanDataRaw <- Filter(function(x) !all(is.na(x)), LoanDataRaw)
library(readr)
LoanData <- read_csv("~/Downloads/LoanData.csv")
View(LoanData)
summary(LoanData)
library(lubridate)
library(ggplot2)
library(dplyr)
library(lubridate)
library(ggplot2)
library(dplyr)
library(stringr)
library(caret)
library(rpart)
library(rattle)
library(ROSE)
library(ROCR)
library(MASS)
library(ipred)
library(plyr)
library(rpart.plot)
install.packages(c("BH", "class", "clipr", "codetools", "colorspace", "curl", "data.table", "dbplyr", "foreign", "gclus", "lattice", "MASS", "Matrix", "mgcv", "openssl", "pillar", "prabclus", "readr", "readxl", "rlang", "rsconnect", "rstudioapi", "survival", "tibble", "tinytex"))
install.packages(c("BH", "class", "clipr", "codetools", "colorspace", "curl", "data.table", "dbplyr", "foreign", "gclus", "lattice", "MASS", "Matrix", "mgcv", "openssl", "pillar", "prabclus", "readr", "readxl", "rlang", "rsconnect", "rstudioapi", "survival", "tibble", "tinytex"))
install.packages(c("BH", "class", "clipr", "codetools", "colorspace", "curl", "data.table", "dbplyr", "foreign", "gclus", "lattice", "MASS", "Matrix", "mgcv", "openssl", "pillar", "prabclus", "readr", "readxl", "rlang", "rsconnect", "rstudioapi", "survival", "tibble", "tinytex"))
load(("~/Download/LendingLoan.csv"))
load(("~/Download/LoanData.csv"))
LoanData<- read.csv("~/Download/LoanData")
library(readr)
LoanData <- read_csv("~/Downloads/LoanData.csv")
View(LoanData)
levels(LoanData$loan_status)
levels(LoanData$loan_status)
`levels<-`(LoanData$loan_status)
table(LoanData$loan_status)
# further clearing the data
LoanData$issue_d <- as.character(LoanData$issue_d)
loans$issue_d <- paste(loans$issue_d, "-01", sep = "")
loans$issue_d <- parse_date_time(loans$issue_d, "myd")
loans$earliest_cr_line <- as.character(loans$earliest_cr_line)
loans$earliest_cr_line <- paste(loans$earliest_cr_line, "-01", sep = "")
loans$earliest_cr_line <- parse_date_time(loans$earliest_cr_line, "myd")
loans$time_since_first_credit <- loans$issue_d - loans$earliest_cr_line
loans$time_since_first_credit <- as.numeric(loans$time_since_first_credit)
loans <- loans %>% filter(time_since_first_credit > 0)
head(loans$time_since_first_credit)
[1]
table(LoanData$loan_status, LoanData$grade)
savehistory("~/Desktop/r_code.Rhistory")
